---
layout: post
title: 机器学习-线性模型
date: 2018-05-21
tags: Machine Learning   
---
### 线性回归

给定数据集$$D=\left\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\right\}$$, 其中$$x_i=(x_{i1};x_{i2};...;x_{id}), y_i \in \mathbb{R}$$, 线性回归模型学得一个现行模型以尽可能准确的预测真实值输出. 即

$$f(x_i)=wx_i+b, f(x_i)\simeq y_i$$

其中w, b为待学习的参数,通过最小化均方误差确定w和b的值:

$$(w^*,b^*) = \arg\min_{(w,b)}\sum_{i=1}^m(f(x_i)-y_i)^2=\arg\min_{(w,b)}\sum_{i=1}^m(y_i-wx_i-b)^2$$

求上式极值直接对w, b求偏导得到:

$$\frac{\partial E_{(w,b)}}{\partial w}=2\left(w\sum_{i=1}^m x_i^2-\sum_{i=1}^m(y_i-b)x_i\right)$$

$$\frac{\partial E_{(w,b)}}{\partial b}=2\left(mb-\sum_{i=1}^m(y_i-wx_i)\right)$$

另上式都等于0, 可求得闭式解:

$$w=\frac{\sum_{i=1}^m y_i(x_i-\bar x)}{\sum_{i=1}^m x_i^2 - \frac{1}{m}\left(\sum_{i=1}^m x_i\right)^2}$$

$$b = \frac{1}{m}\sum_{i=1}^m(y_i-wx_i)$$

